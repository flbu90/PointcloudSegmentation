{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Script ist f√ºr die Segmentierung von Punktwolken ohne Ground Truth Informationen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Model with Voxelsize of 256 has been loaded.\n"
     ]
    }
   ],
   "source": [
    "from pyntcloud import PyntCloud\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randint, uniform\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import time\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import calinski_harabasz_score # the higher the better\n",
    "\n",
    "import open3d as o3d\n",
    "import scipy.io as io\n",
    "import scipy.ndimage as nd\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ User Settings ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# Set size of Voxels. The higher the better but can also be very slow with big Pointclouds\n",
    "voxel_size = 256\n",
    "\n",
    "# Restore the trained model\n",
    "if (voxel_size == 64):\n",
    "    model = tf.keras.models.load_model('savedmodel/scannet_model_64.h5')\n",
    "    print(\"CNN Model with Voxelsize of 64 has been loaded.\")\n",
    "\n",
    "if (voxel_size == 128):\n",
    "    model = tf.keras.models.load_model('savedmodel/scannet_model_128.h5')\n",
    "    print(\"CNN Model with Voxelsize of 128 has been loaded.\")\n",
    "    \n",
    "if (voxel_size == 192):\n",
    "    model = tf.keras.models.load_model('savedmodel/scannet_model_192.h5')\n",
    "    print(\"CNN Model with Voxelsize of 192 has been loaded.\")\n",
    "\n",
    "if (voxel_size == 256):\n",
    "    model = tf.keras.models.load_model('savedmodel/scannet_model_256.h5')\n",
    "    print(\"CNN Model with Voxelsize of 256 has been loaded.\")\n",
    "          \n",
    "# Clustering number of candidates 0-7\n",
    "# 0 ^= 1x Gaussian Mixture Candidate and 1x Bayesian Mixture Candidate\n",
    "# The more points the pointcloud has the lower the nb of candidates should be\n",
    "n_candidates = 3\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Functions ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "# Colorizes the different Clusters randomly\n",
    "def colorize_pc(number_clusterpoints):\n",
    "\n",
    "    rgb = np.zeros((number_clusterpoints, 3), dtype=int)\n",
    "\n",
    "    r = randint(0, 254)\n",
    "    g = randint(0, 254)\n",
    "    b = randint(0, 254)\n",
    "\n",
    "    rgb_temp = np.array((r,g,b))\n",
    "    rgb = np.full_like(rgb,rgb_temp)\n",
    "\n",
    "    return rgb\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# Adding the Clusterlabel to the Clusters\n",
    "def add_clusterlabel(number_clusterpoints, clusterlabel):\n",
    "    \n",
    "    clusterlabel_array = np.zeros((number_clusterpoints,1), dtype=int)\n",
    "    clusterlabel_temp = np.array(clusterlabel)\n",
    "    clusterlabel_array = np.full_like(clusterlabel_array, clusterlabel_temp)\n",
    "    \n",
    "    return clusterlabel_array\n",
    "    \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# Colorize the points and returns a dataframe with rgb and a dataframe with labels\n",
    "def colorize_to_dataframe(clusters_dict, cnn_prediction):\n",
    "    \n",
    "    # Placeholder for the colorized Clusterscene (x,y,z,r,b,g(segment color), cluster_label)\n",
    "    cluster_scene = np.zeros((0, 7), dtype=float)\n",
    "    \n",
    "    clusterlabel = 0\n",
    "    for clusterlabel in range(cnn_prediction):\n",
    "        cluster = clusters_dict[clusterlabel]\n",
    "        number_clusterpoints = cluster.shape[0]\n",
    "        colorize_rgb = colorize_pc(number_clusterpoints)\n",
    "        \n",
    "        # Adding Color to cluster\n",
    "        cluster = np.hstack((cluster, colorize_rgb))\n",
    "\n",
    "        #Adding Clusterlabel to Cluster\n",
    "        cluster_label = add_clusterlabel(number_clusterpoints, clusterlabel)\n",
    "        cluster = np.hstack((cluster, cluster_label))\n",
    "        cluster_scene = np.append(cluster_scene, cluster, axis=0)\n",
    "         \n",
    "    x = cluster_scene[:, 0]\n",
    "    y = cluster_scene[:, 1]\n",
    "    z = cluster_scene[:, 2]\n",
    "    # Segment rgb Color\n",
    "    red = cluster_scene[:, 3]\n",
    "    green = cluster_scene[:, 4]\n",
    "    blue = cluster_scene[:, 5]\n",
    "    # Cluster Label\n",
    "    cluster_label = cluster_scene[:, 6]\n",
    "\n",
    "    df_cluster_scene_rgb = pd.DataFrame(zip(x, y, z, red, green, blue), columns=[\"x\", \"y\", \"z\", \"red\", \"green\", \"blue\"])\n",
    "    df_cluster_scene_labels = pd.DataFrame(zip(x, y, z, cluster_label), columns=[\"x\", \"y\", \"z\",\"cluster_label\"])\n",
    "    npy_cluster_scene_labels = df_cluster_scene_labels.to_numpy()\n",
    "        \n",
    "    return df_cluster_scene_rgb, npy_cluster_scene_labels\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# load data from cvs    \n",
    "def load_cvs_data(path):\n",
    "    return np.loadtxt(path,delimiter=';')\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "def bubble_sort(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        for j in range(0, n-i-1):\n",
    "            # relative max occurence of label: arr[j][3][0]/arr[j][1]\n",
    "            #if arr[j][3][0]/arr[j][1] < arr[j+1][3][0]/arr[j+1][1]:\n",
    "            if arr[j][3].max() < arr[j+1][3].max():\n",
    "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
    "    return arr\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "def downsample_pointcloud(pointcloud, coeff):\n",
    "    return pointcloud[::coeff]\n",
    "    pass\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "def display_inlier_outlier(cloud, ind):\n",
    "    inlier_cloud = cloud.select_down_sample(ind)\n",
    "    outlier_cloud = cloud.select_down_sample(ind, invert=True)\n",
    "\n",
    "    print(\"Showing outliers (red) and inliers (gray): \")\n",
    "    outlier_cloud.paint_uniform_color([1, 0, 0])\n",
    "    inlier_cloud.paint_uniform_color([0.8, 0.8, 0.8])\n",
    "    o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud])\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "def pc_normalize(pointcloud):\n",
    "    \n",
    "    l = pointcloud.shape[0]\n",
    "    centroid = np.mean(pointcloud, axis=0)\n",
    "    pointcloud = pointcloud - centroid\n",
    "    m = np.max(np.sqrt(np.sum(pointcloud**2, axis=1)))\n",
    "    pointcloud = pointcloud / m\n",
    "    return pointcloud\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "def get_assignments(best_clusterscene, clusterscene):\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    k = 0\n",
    "\n",
    "    assignments = defaultdict(dict)\n",
    "    n_true_points_segment = {}\n",
    "    seg_max  = 0\n",
    "\n",
    "    while i < (cnn_prediction): # i = number of segments/objects for best clusterscene\n",
    "\n",
    "        # Get the first \"best\" segment\n",
    "        best_segment = best_clusterscene[np.where(best_clusterscene[:,3] == i)]\n",
    "        best_segment = np.delete(best_segment, 3, axis=1) # delete unnecessary label information\n",
    "        \n",
    "        n_points_best_segment = best_segment.shape[0] # get number of points of segment\n",
    "       \n",
    "        while j <= n_candidates: # j = number of Candidates\n",
    "                   \n",
    "            while k < (cnn_prediction): # k = number of segments/objects of all clusterings\n",
    "                \n",
    "                # get the segment\n",
    "                segment = clusterscene[j][np.where(clusterscene[j][:,3] == k)]\n",
    "                segment = np.delete(segment, 3, axis=1)\n",
    "                \n",
    "                # count number of matching points \n",
    "                result = np.isin(best_segment, segment)\n",
    "                n_true_points = 0\n",
    "                for r in result:\n",
    "                    if(np.all(r)):\n",
    "                        n_true_points = n_true_points + 1\n",
    "\n",
    "                # store all true points per segment in array for max calulation\n",
    "                n_true_points_segment[k] = n_true_points \n",
    "                \n",
    "                # score calculation\n",
    "                segment_score = (n_true_points_segment[k] / n_points_best_segment) * 100 \n",
    "                segment_score = round(segment_score)\n",
    "                \n",
    "                # Output:  max of matching Points, real number of points, assignment, segment score\n",
    "                if seg_max == 0:\n",
    "                    assignments[j][i] = [n_true_points_segment[k]], [best_segment.shape[0]], [i], [k], [segment_score]\n",
    "\n",
    "                elif n_true_points_segment[k] > seg_max:\n",
    "                    assignments[j][i] = [n_true_points_segment[k]], [best_segment.shape[0]], [i], [k], [segment_score]\n",
    "\n",
    "                seg_max = n_true_points_segment[max(n_true_points_segment, key=n_true_points_segment.get)] \n",
    "                \n",
    "                k = k + 1\n",
    "\n",
    "            n_true_points_segment.clear()\n",
    "            seg_max  = 0\n",
    "            k = 0\n",
    "            j = j + 1\n",
    "        \n",
    "        i = i + 1\n",
    "        j = 0\n",
    "        k = 0    \n",
    "    return assignments\n",
    "    \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "def homogenity_check(gm_assignments, bm_assignments):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    gm_score = 0\n",
    "    bm_score = 0\n",
    "    \n",
    "    # First go trough all the Candidates  \n",
    "    while j <= n_candidates: # j = number of Candidates\n",
    "        while i < (cnn_prediction): # i = number of Segments / Objects         \n",
    "            \n",
    "            # Get the sement score\n",
    "            gm_segment_score = gm_assignments[j][i][4][0]\n",
    "            bm_segment_score = bm_assignments[j][i][4][0] \n",
    "            \n",
    "            # += all points in Cluster\n",
    "            gm_score += gm_segment_score\n",
    "            bm_score += bm_segment_score\n",
    "            \n",
    "            i = i + 1\n",
    "        \n",
    "        i = 0\n",
    "        j = j + 1\n",
    "    \n",
    "    homogenity = (((gm_score + bm_score - (cnn_prediction*100))/(((n_candidates + 1)* 2) - 1)) / (cnn_prediction*100))*100\n",
    "    return round(homogenity,2)\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# Restore RGB Information\n",
    "def restore_real_rgb(best_clusterscene, pointcloud):\n",
    "    \n",
    "    n_points = best_clusterscene.shape[0]\n",
    "    final_clusterscene = np.empty((n_points,7))\n",
    "\n",
    "    bx = best_clusterscene[:,0]\n",
    "    by = best_clusterscene[:,1]\n",
    "    bz = best_clusterscene[:,2]\n",
    "    blabel = best_clusterscene[:,3]\n",
    "\n",
    "    npy_pointcloud = pointcloud.points.to_numpy()\n",
    "    \n",
    "    # Initial Pointcloud after size manipulations\n",
    "    ix = npy_pointcloud[:,0]\n",
    "    iy = npy_pointcloud[:,1]\n",
    "    iz = npy_pointcloud[:,2]\n",
    "    \n",
    "    ir = npy_pointcloud[:,3]\n",
    "    ig = npy_pointcloud[:,4]\n",
    "    ib = npy_pointcloud[:,5]\n",
    "    \n",
    "    i=0\n",
    "    j=0\n",
    "    \n",
    "    # This takes a long time and needs to be simplyfied. \n",
    "    \n",
    "    while i < n_points:\n",
    "        while j < n_points:\n",
    "            \n",
    "            if bx[i] == ix[j] and by[i] == iy[j] and bz[i] == iz[j]:\n",
    "                temp = [bx[i], by[i], bz[i], ir[j], ig[j], ib[j], blabel[i]]\n",
    "                final_clusterscene[i] = temp\n",
    "                i+=1\n",
    "                j=n_points+1 # Stop the loop when xyz match is found and continue with next i\n",
    "            else: \n",
    "                j+=1\n",
    "                \n",
    "                \n",
    "            \"\"\"\n",
    "            intersect = np.intersect1d(npy_best_clusterscene[i], pointcloud.xyz[j], assume_unique=True) # compares the Arrays\n",
    "            if(intersect.shape[0] == 3):\n",
    "                temp = np.append(npy_pointcloud[j], blabel[j])\n",
    "                final_clusterscene[i] = temp\n",
    "                i += 1   \n",
    "            \"\"\"\n",
    "        j = 0\n",
    "\n",
    "    return final_clusterscene\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# Converts any numpy pointcloud array to a PyntCloud object. \n",
    "def numpy_to_pyntcloud(pointcloud, normalized_rgb):\n",
    "    \n",
    "    pc_dimension = pointcloud.shape[1]\n",
    "    \n",
    "    if(pc_dimension == 0 or pc_dimension == 1 or pc_dimension == 2):\n",
    "        print(\"Error. Pointcloud must have at least XYZ-Informations.\")\n",
    "    \n",
    "    else :\n",
    "        \n",
    "        if (pc_dimension == 3):\n",
    "            print(\"Creating an X,Y,Z Pyntcloud.\")\n",
    "            x = pointcloud[:, 0]\n",
    "            y = pointcloud[:, 1]\n",
    "            z = pointcloud[:, 2]\n",
    "            \n",
    "            df_output_pc = pd.DataFrame(zip(x, y, z), columns=['x', 'y', 'z'])\n",
    "            output_pc = PyntCloud(df_output_pc)\n",
    "        \n",
    "        if (pc_dimension == 4):\n",
    "            print(\"Creating an X,Y,Z,Label Pyntcloud.\")\n",
    "            x = pointcloud[:, 0]\n",
    "            y = pointcloud[:, 1]\n",
    "            z = pointcloud[:, 2]\n",
    "            label = pointcloud[:, 3]\n",
    "            \n",
    "            df_output_pc = pd.DataFrame(zip(x, y, z, label), columns=['x', 'y', 'z','label'])\n",
    "            output_pc = PyntCloud(df_output_pc)\n",
    "        \n",
    "        if (pc_dimension == 5):\n",
    "            print(\"Error.Invalid Pointcloud dimension.\")\n",
    "        \n",
    "        if (pc_dimension == 6):\n",
    "            print(\"Creating an X,Y,Z,R,G,B Pyntcloud.\")\n",
    "            x = pointcloud[:, 0]\n",
    "            y = pointcloud[:, 1]\n",
    "            z = pointcloud[:, 2]\n",
    "            \n",
    "            if (normalized_rgb !=1):\n",
    "                print(\"Creating an X,Y,Z,R,G,B Pyntcloud.\")\n",
    "                r = pointcloud[:, 3]\n",
    "                g = pointcloud[:, 4]\n",
    "                b = pointcloud[:, 5]\n",
    "            else:\n",
    "                print(\"Creating an X,Y,Z,R,G,B Pyntcloud. With normalized RGB\")\n",
    "                r = pointcloud[:, 3]/255\n",
    "                g = pointcloud[:, 4]/255\n",
    "                b = pointcloud[:, 5]/255\n",
    "                \n",
    "            \n",
    "            df_output_pc = pd.DataFrame(zip(x, y, z, r, g, b), columns=['x', 'y', 'z','red', 'green', 'blue'])\n",
    "            output_pc = PyntCloud(df_output_pc)\n",
    "        \n",
    "        if (pc_dimension == 7):\n",
    "            x = pointcloud[:, 0]\n",
    "            y = pointcloud[:, 1]\n",
    "            z = pointcloud[:, 2]\n",
    "            \n",
    "            if (normalized_rgb !=1):\n",
    "                print(\"Creating an X,Y,Z,R,G,B, Label Pyntcloud.\")\n",
    "                r = pointcloud[:, 3]\n",
    "                g = pointcloud[:, 4]\n",
    "                b = pointcloud[:, 5]\n",
    "            else:\n",
    "                print(\"Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\")\n",
    "                r = pointcloud[:, 3]/255\n",
    "                g = pointcloud[:, 4]/255\n",
    "                b = pointcloud[:, 5]/255\n",
    "                \n",
    "            label = pointcloud[:, 6]\n",
    "\n",
    "            df_output_pc = pd.DataFrame(zip(x, y, z, r, g, b, label), columns=['x', 'y', 'z','red', 'green', 'blue','label'])\n",
    "            output_pc = PyntCloud(df_output_pc)\n",
    "\n",
    "    return output_pc\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# Exports the final Pointcloud to .ply files\n",
    "def export_to_ply(final_clusterscene, normalized_rgb):\n",
    "    \n",
    "    i = 0\n",
    "    for i in range(cnn_prediction): # go trough all clusters\n",
    "\n",
    "        final_segment = final_clusterscene[np.where(final_clusterscene[:,6] == i)]\n",
    "        final_segment = numpy_to_pyntcloud(final_segment, normalized_rgb)\n",
    "        \n",
    "        path = \"cluster_\"+str(i)+\".ply\"\n",
    "        final_segment.to_file(path)\n",
    "        \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# Cluster to mesh BETA. This function doesn't work yet. \n",
    "# Maybe because the convex hull algorithm of pyntcloud makes the mesh waterproof. \n",
    "\n",
    "def cluster_to_mesh(final_clusterscene):\n",
    "    i = 0\n",
    "    for i in range(cnn_prediction): # go trough all clusters\n",
    "\n",
    "        final_segment = final_clusterscene[np.where(final_clusterscene[:,6] == i)]\n",
    "        final_segment = numpy_to_pyntcloud(final_segment, normalized_rgb)\n",
    "        \n",
    "        # Create mesh Pyntcloud structure\n",
    "        mesh_id= final_segment.add_structure(\"convex_hull\", qhull_options=\"Qt\")\n",
    "        segment_mesh = final_segment.structures[mesh_id]\n",
    "\n",
    "        segment_mesh = segment_mesh.get_mesh() # Creates a dataframe with v1,v2,v3\n",
    "\n",
    "        final_mesh = PyntCloud(df_final_segment, mesh=segment_mesh)\n",
    "\n",
    "        path = \"cluster\"+str(i)+\".ply\"\n",
    "        final_mesh.to_file(path, also_save=[\"mesh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Numbers of Objects: 15\n"
     ]
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Start  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "DATADIR = \"data\\lidar\\\\\"\n",
    "file = \"KleinerKonfiEcke_010.ply\"\n",
    "path = DATADIR + file\n",
    "\n",
    "pointcloud = PyntCloud.from_file(path)  #Format: x,y,z, r, g, b\n",
    "initial_pointcloud = PyntCloud.from_file(path) # Stays untouched for error calculation\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Input raw Pointcloud into CNN ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# Voxelgrid only takes the XYZ Informations\n",
    "voxelgrid_id = pointcloud.add_structure(\"voxelgrid\", n_x = voxel_size, n_y = voxel_size, n_z = voxel_size)\n",
    "voxelscene = pointcloud.structures[voxelgrid_id]\n",
    "\n",
    "# Create binary array from Voxelscene\n",
    "binary_voxelscene = voxelscene.get_feature_vector(mode=\"binary\")\n",
    "\n",
    "# Prepare data for Network input\n",
    "# A 3D Cnn expects an 4D Tensor as Input \n",
    "binary_voxelscene = np.expand_dims(binary_voxelscene, axis=0)\n",
    "\n",
    "# CNN prediction\n",
    "cnn_out = model.predict(binary_voxelscene)\n",
    "cnn_prediction = np.argmax(cnn_out)\n",
    "\n",
    "print(\"Predicted Numbers of Objects:\", cnn_prediction)\n",
    "\n",
    "#voxelscene.plot(d=3, mode=\"density\", cmap=\"hsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pointcloud with 917756 points is too big for segmentation.\n",
      "Downsampling the Pointcloud to 2500  points.\n",
      "Pointcloud after downsampling and outliner removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Florian\\.conda\\envs\\busch\\lib\\site-packages\\pythreejs\\traits.py:191: UserWarning: 64-bit data types not supported for WebGL data, casting to 32-bit.\n",
      "  warnings.warn('64-bit data types not supported for WebGL '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ffef9c59554f6fb5d477b4ed1d26fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(-0.007297606143681331, 0.7899786032540111, 0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f37b17ec16c45beb53f98a4783aa9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.014, max=0.14, step=0.00014000000000000001), La‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Prepare Pointcloud for Clustering ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "n_points = pointcloud.points.shape[0]\n",
    "\n",
    "# Downsamling for better performance. \n",
    "# 25000 is only for showcasing the differen cluster candidates. \n",
    "# For real usage 250.000 points with candidates = 1 is a good start\n",
    "if(n_points > 2500):\n",
    "    downsample_coeff = n_points / 2500\n",
    "    \n",
    "    print(\"Pointcloud with\", n_points, \"points is too big for segmentation.\")\n",
    "    print(\"Downsampling the Pointcloud to\", round(n_points/downsample_coeff),\" points.\" )\n",
    "    \n",
    "    pointcloud = downsample_pointcloud(pointcloud.points, round(downsample_coeff))\n",
    "    pointcloud = pointcloud.to_numpy()\n",
    "else: \n",
    "    pointcloud = pointcloud.points.to_numpy()\n",
    "\n",
    "\n",
    "# Preparing Pointcloud for input in o3d. Colors have to be in r,g,b and in range 0-1    \n",
    "p_x = pointcloud[:, 0]\n",
    "p_y = pointcloud[:, 1]\n",
    "p_z = pointcloud[:, 2]\n",
    "\n",
    "p_r = pointcloud[:, 3] / 255\n",
    "p_g = pointcloud[:, 4] / 255 \n",
    "p_b = pointcloud[:, 5] / 255\n",
    "\n",
    "df_pointcloud_xyz = pd.DataFrame(zip(p_x, p_y, p_z), columns=['x', 'y', 'z']) \n",
    "df_pointcloud_rgb = pd.DataFrame(zip(p_r, p_g, p_b), columns=['r','g','b']) \n",
    "\n",
    "pointcloud_xyz = df_pointcloud_xyz.to_numpy()\n",
    "pointcloud_xyz = pc_normalize(pointcloud_xyz)\n",
    "pointcloud_rgb = df_pointcloud_rgb.to_numpy()\n",
    "\n",
    "# Create Outliner Removal o3 \n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pointcloud_xyz)\n",
    "pcd.colors = o3d.utility.Vector3dVector(pointcloud_rgb)\n",
    "\n",
    "# the lower std_ration the more agressive is the outliner removal\n",
    "cl, ind = pcd.remove_statistical_outlier(nb_neighbors=80, std_ratio=3.0)\n",
    "\n",
    "#display_inlier_outlier(pcd, ind)\n",
    "\n",
    "#back to numpy array\n",
    "pointcloud_xyz = np.asarray(cl.points)\n",
    "pointcloud_rgb = np.asarray(cl.colors)\n",
    "\n",
    "x = (pointcloud_xyz[:, 0])\n",
    "y = (pointcloud_xyz[:, 1])\n",
    "z = (pointcloud_xyz[:, 2])\n",
    "\n",
    "r = (pointcloud_rgb[:, 0]) *255\n",
    "g = (pointcloud_rgb[:, 1]) *255\n",
    "b = (pointcloud_rgb[:, 2]) *255\n",
    "\n",
    "# In Pyntcloud color has to be 'red', 'green', 'blue' and in range 0-255\n",
    "df_pointcloud = pd.DataFrame(zip(x, y, z, r, g, b), columns=['x', 'y', 'z','red','green','blue'])\n",
    "pointcloud = PyntCloud(df_pointcloud)\n",
    "\n",
    "print(\"Pointcloud after downsampling and outliner removal\")\n",
    "pointcloud.plot(initial_point_size=0.014)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First candidate and second candidate:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Florian\\.conda\\envs\\busch\\lib\\site-packages\\pythreejs\\traits.py:191: UserWarning: 64-bit data types not supported for WebGL data, casting to 32-bit.\n",
      "  warnings.warn('64-bit data types not supported for WebGL '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b52d934815444acb34091ac5d1ad840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(-0.007297606143681331, 0.7899786032540111, 0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1d1662496a4702a1b10f2481fb5815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.1, max=1.0, step=0.001), Label(value='Backgroun‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b292a5cb39548dc9ea5e92b91d7412b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(-0.007297606143681342, 0.7899786032540111, 0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ea5c46ec434e0e9601091febdd1962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.1, max=1.0, step=0.001), Label(value='Backgroun‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2 from 8 done.\n",
      "Thrid candidate and fourth candidate:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Florian\\.conda\\envs\\busch\\lib\\site-packages\\pythreejs\\traits.py:191: UserWarning: 64-bit data types not supported for WebGL data, casting to 32-bit.\n",
      "  warnings.warn('64-bit data types not supported for WebGL '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da5e5eac0aa49b09519d1bb22ccdff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(-0.0072976061436813445, 0.7899786032540111, ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca19c77b312349a49a2700b2b47adeca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.1, max=1.0, step=0.001), Label(value='Backgroun‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b00891c8fb64154a5ac045e6e381aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(-0.007297606143681336, 0.7899786032540111, 0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16b9b460bd14c42823ad73f1d8f8c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.1, max=1.0, step=0.001), Label(value='Backgroun‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 4 from 8 done.\n",
      "Fifth candidate and sixths candidate:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Florian\\.conda\\envs\\busch\\lib\\site-packages\\pythreejs\\traits.py:191: UserWarning: 64-bit data types not supported for WebGL data, casting to 32-bit.\n",
      "  warnings.warn('64-bit data types not supported for WebGL '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27893e020b0b4c8bae0b08fd61f324ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(-0.007297606143681336, 0.789978603254011, 0.‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c57437ae93e4665a469ae40d107858e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.1, max=1.0, step=0.001), Label(value='Backgroun‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988ba3aba1ea4e408deac93e096848a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(-0.007297606143681342, 0.7899786032540111, 0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e822e42a6da494aad949ade07919999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.1, max=1.0, step=0.001), Label(value='Backgroun‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 6 from 8 done.\n",
      "Seventh candidate and eights candidate:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Florian\\.conda\\envs\\busch\\lib\\site-packages\\pythreejs\\traits.py:191: UserWarning: 64-bit data types not supported for WebGL data, casting to 32-bit.\n",
      "  warnings.warn('64-bit data types not supported for WebGL '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ed0b8cedbe402e8587131ecf065e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(-0.007297606143681353, 0.7899786032540111, 0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7228ffa28dd34efcafbaad7e8cbbca58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.1, max=1.0, step=0.001), Label(value='Backgroun‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c6893769444c148abb97eda106799b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(-0.007297606143681336, 0.7899786032540111, 0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522aa9ad66dc40528b729b567307b369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.1, max=1.0, step=0.001), Label(value='Backgroun‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 8 from 8 done.\n",
      "Segmentation done\n"
     ]
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ CLUSTERING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "#Prepare Pointcloud for Clustering\n",
    "cluster_pointcloud = pointcloud.xyz\n",
    "\n",
    "# Setting up the Clustering Candidates\n",
    "gaussian_clustering = GaussianMixture(n_components=cnn_prediction, covariance_type='full',tol=1e-5, max_iter=600)\n",
    "bayesian_clustering = BayesianGaussianMixture(n_components=cnn_prediction, \n",
    "                                              covariance_type='full',tol=1e-5, max_iter=600)\n",
    "\n",
    "gaussian_clustering2 = GaussianMixture(n_components=cnn_prediction, covariance_type='full',tol=1e-6, max_iter=700)\n",
    "bayesian_clustering2 = BayesianGaussianMixture(n_components=cnn_prediction, \n",
    "                                               covariance_type='full',tol=1e-6, max_iter=700)\n",
    "\n",
    "gaussian_clustering3 = GaussianMixture(n_components=cnn_prediction, covariance_type='full',tol=1e-6, max_iter=800)\n",
    "bayesian_clustering3 = BayesianGaussianMixture(n_components=cnn_prediction, \n",
    "                                               covariance_type='full',tol=1e-6, max_iter=800)\n",
    "\n",
    "gaussian_clustering4 = GaussianMixture(n_components=cnn_prediction, covariance_type='full',tol=1e-7, max_iter=1000)\n",
    "bayesian_clustering4= BayesianGaussianMixture(n_components=cnn_prediction, \n",
    "                                              covariance_type='full',tol=1e-7, max_iter=1000)\n",
    "\n",
    "gaussian_clustering5 = GaussianMixture(n_components=cnn_prediction, covariance_type='full',tol=1e-8, max_iter=1500)\n",
    "bayesian_clustering5 = BayesianGaussianMixture(n_components=cnn_prediction, \n",
    "                                              covariance_type='full',tol=1e-8, max_iter=1500)\n",
    "\n",
    "gaussian_clustering6 = GaussianMixture(n_components=cnn_prediction, covariance_type='full',tol=1e-9, max_iter=2000)\n",
    "bayesian_clustering6 = BayesianGaussianMixture(n_components=cnn_prediction,\n",
    "                                              covariance_type='full',tol=1e-9, max_iter=2000)\n",
    "\n",
    "gaussian_clustering7 = GaussianMixture(n_components=cnn_prediction, covariance_type='diag',tol=1e-4, max_iter=500)\n",
    "bayesian_clustering7 = BayesianGaussianMixture(n_components=cnn_prediction,\n",
    "                                              covariance_type='diag',tol=1e-4, max_iter=500)\n",
    "\n",
    "gaussian_clustering8 = GaussianMixture(n_components=cnn_prediction, covariance_type='diag',tol=1e-6, max_iter=800)\n",
    "bayesian_clustering8 = BayesianGaussianMixture(n_components=cnn_prediction,\n",
    "                                              covariance_type='diag',tol=1e-6, max_iter=800)\n",
    "\n",
    "# List of Labels per Clustering\n",
    "gm ={}\n",
    "gm_labels={}\n",
    "bm={}\n",
    "bm_labels={}\n",
    "\n",
    "gm_clusters_dict={}\n",
    "gm_clusterscene_rgb={}\n",
    "gm_clusterscene_labels={}\n",
    "\n",
    "bm_clusters_dict={}\n",
    "bm_clusterscene_rgb={}\n",
    "bm_clusterscene_labels={}\n",
    "\n",
    "gm_clusterscene_rgb_pynt={}\n",
    "bm_clusterscene_rgb_pynt ={}\n",
    "\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "while i <= n_candidates:\n",
    "    \n",
    "    if i == 0:\n",
    "        print(\"First candidate and second candidate:\")\n",
    "        gm[i] = gaussian_clustering.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering.predict(cluster_pointcloud) \n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        \n",
    "    if i == 1:\n",
    "        print(\"Thrid candidate and fourth candidate:\")\n",
    "        gm[i] = gaussian_clustering2.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering2.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering2.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering2.predict(cluster_pointcloud)\n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        \n",
    "    if i == 2:\n",
    "        print(\"Fifth candidate and sixths candidate:\")\n",
    "        gm[i] = gaussian_clustering3.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering3.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering3.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering3.predict(cluster_pointcloud)\n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        \n",
    "    if i == 3:\n",
    "        print(\"Seventh candidate and eights candidate:\")\n",
    "        gm[i] = gaussian_clustering4.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering4.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering4.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering4.predict(cluster_pointcloud)\n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        \n",
    "    if i == 4:\n",
    "        print(\"Ninth candidate and tenth candidate:\")        \n",
    "        gm[i] = gaussian_clustering5.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering5.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering5.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering5.predict(cluster_pointcloud)\n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        \n",
    "    if i == 5:\n",
    "        print(\"Eleventh candidate and twelfth candidate:\")        \n",
    "        gm[i] = gaussian_clustering6.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering6.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering6.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering6.predict(cluster_pointcloud)\n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "    \n",
    "    if i == 6:\n",
    "        print(\"Thirteeth candidate and fourteenth candidate:\")        \n",
    "        gm[i] = gaussian_clustering7.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering7.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering7.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering7.predict(cluster_pointcloud)\n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "    \n",
    "    if i == 5:\n",
    "        print(\"Fifteenth candidate and sixteenth candidate:\")        \n",
    "        gm[i] = gaussian_clustering8.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering8.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering8.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering8.predict(cluster_pointcloud)\n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        \n",
    "    # Colorize Clusters and adding Clusterlabels\n",
    "    \n",
    "    gm_clusterscene_rgb[i], gm_clusterscene_labels[i] = colorize_to_dataframe(gm_clusters_dict[i], cnn_prediction)\n",
    "    bm_clusterscene_rgb[i], bm_clusterscene_labels[i] = colorize_to_dataframe(bm_clusters_dict[i], cnn_prediction)\n",
    "    \n",
    "    gm_clusterscene_rgb_pynt[i] = PyntCloud(gm_clusterscene_rgb[i])\n",
    "    bm_clusterscene_rgb_pynt[i] = PyntCloud(bm_clusterscene_rgb[i])\n",
    "    \n",
    "    gm_clusterscene_rgb_pynt[i].plot(initial_point_size=0.1)\n",
    "    bm_clusterscene_rgb_pynt[i].plot(initial_point_size=0.1)\n",
    "    \n",
    "    print(\"Cluster\", (i+1)*2, \"from\", (n_candidates+1)*2, \"done.\")\n",
    "\n",
    "    i=i+1\n",
    "    \n",
    "print(\"Segmentation done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 247.2061640783901\n",
      "2nd Best Score: 215.90003819293668\n"
     ]
    }
   ],
   "source": [
    "# Cluster Validation \n",
    "i = 0\n",
    "max_calinski_score = 0\n",
    "max2_calinski_score = 0 # Second best score\n",
    "\n",
    "gm_calinski_score = []\n",
    "bm_calinski_score = []\n",
    "\n",
    "while i <= n_candidates:\n",
    "    \n",
    "    gm_calinski_score.append(calinski_harabasz_score(cluster_pointcloud, gm_clusterscene_labels[i][:,3]))\n",
    "    bm_calinski_score.append(calinski_harabasz_score(cluster_pointcloud, bm_clusterscene_labels[i][:,3]))\n",
    "    \n",
    "    #print(gm_calinski_score[i], bm_calinski_score[i]) \n",
    "    i = i + 1\n",
    "    \n",
    "# get max   \n",
    "gm_max =  max(gm_calinski_score)\n",
    "\n",
    "gm_calinski_score_temp = set(gm_calinski_score) \n",
    "# removing the largest element from temp list \n",
    "gm_calinski_score_temp.remove(gm_max) \n",
    "# get 2nd max\n",
    "gm_2max = max(gm_calinski_score_temp)\n",
    "\n",
    "#-----------------------------------------------\n",
    "# get max \n",
    "bm_max =  max(bm_calinski_score)\n",
    "\n",
    "bm_calinski_score_temp = set(bm_calinski_score) \n",
    "bm_calinski_score_temp.remove(bm_max) \n",
    "# get 2nd max\n",
    "bm_2max = max(bm_calinski_score_temp)\n",
    "\n",
    "if (gm_max > bm_max):\n",
    "    index_max = gm_calinski_score.index(gm_max)\n",
    "    best_clusterscene = gm_clusterscene_labels[index_max]\n",
    "else: \n",
    "    index_max = bm_calinski_score.index(bm_max)\n",
    "    best_clusterscene = bm_clusterscene_labels[index_max]\n",
    "\n",
    "if (gm_2max > bm_2max):\n",
    "    index_2max = gm_calinski_score.index(gm_2max)\n",
    "    best2_clusterscene = gm_clusterscene_labels[index_2max]\n",
    "else: \n",
    "    index_2max = bm_calinski_score.index(bm_2max)\n",
    "    best2_clusterscene = bm_clusterscene_labels[index_2max]\n",
    "\n",
    "#Check\n",
    "print(\"Best Score:\", calinski_harabasz_score(cluster_pointcloud, best_clusterscene[:,3]))\n",
    "print(\"2nd Best Score:\", calinski_harabasz_score(cluster_pointcloud, best2_clusterscene[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get Assignments and Error Calc for best Cluster\n",
    "gm_best_assignments = get_assignments(best_clusterscene, gm_clusterscene_labels)\n",
    "bm_best_assignments = get_assignments(best_clusterscene, bm_clusterscene_labels)\n",
    "\n",
    "# Get Assignments and Error Calc for 2nd best Cluster\n",
    "gm_best2_assignments = get_assignments(best2_clusterscene, gm_clusterscene_labels)\n",
    "bm_best2_assignments = get_assignments(best2_clusterscene, bm_clusterscene_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {0: {0: ([81], [132], [0], [8], [61]),\n",
       "              1: ([49], [83], [1], [5], [59]),\n",
       "              2: ([385], [385], [2], [12], [100]),\n",
       "              3: ([81], [81], [3], [13], [100]),\n",
       "              4: ([112], [113], [4], [0], [99]),\n",
       "              5: ([267], [357], [5], [11], [75]),\n",
       "              6: ([243], [245], [6], [13], [99]),\n",
       "              7: ([38], [39], [7], [3], [97]),\n",
       "              8: ([45], [45], [8], [4], [100]),\n",
       "              9: ([159], [162], [9], [7], [98]),\n",
       "              10: ([85], [101], [10], [9], [84]),\n",
       "              11: ([309], [385], [11], [14], [80]),\n",
       "              12: ([51], [95], [12], [0], [54]),\n",
       "              13: ([33], [34], [13], [2], [97]),\n",
       "              14: ([200], [200], [14], [6], [100])},\n",
       "             1: {0: ([56], [132], [0], [2], [42]),\n",
       "              1: ([83], [83], [1], [3], [100]),\n",
       "              2: ([384], [385], [2], [14], [100]),\n",
       "              3: ([81], [81], [3], [10], [100]),\n",
       "              4: ([101], [113], [4], [1], [89]),\n",
       "              5: ([189], [357], [5], [1], [53]),\n",
       "              6: ([243], [245], [6], [10], [99]),\n",
       "              7: ([36], [39], [7], [4], [92]),\n",
       "              8: ([45], [45], [8], [14], [100]),\n",
       "              9: ([162], [162], [9], [5], [100]),\n",
       "              10: ([92], [101], [10], [6], [91]),\n",
       "              11: ([385], [385], [11], [8], [100]),\n",
       "              12: ([50], [95], [12], [1], [53]),\n",
       "              13: ([34], [34], [13], [9], [100]),\n",
       "              14: ([200], [200], [14], [0], [100])},\n",
       "             2: {0: ([90], [132], [0], [6], [68]),\n",
       "              1: ([83], [83], [1], [0], [100]),\n",
       "              2: ([254], [385], [2], [11], [66]),\n",
       "              3: ([81], [81], [3], [4], [100]),\n",
       "              4: ([71], [113], [4], [2], [63]),\n",
       "              5: ([228], [357], [5], [2], [64]),\n",
       "              6: ([244], [245], [6], [4], [100]),\n",
       "              7: ([36], [39], [7], [3], [92]),\n",
       "              8: ([45], [45], [8], [11], [100]),\n",
       "              9: ([155], [162], [9], [5], [96]),\n",
       "              10: ([94], [101], [10], [14], [93]),\n",
       "              11: ([385], [385], [11], [12], [100]),\n",
       "              12: ([94], [95], [12], [13], [99]),\n",
       "              13: ([22], [34], [13], [0], [65]),\n",
       "              14: ([185], [200], [14], [1], [92])},\n",
       "             3: {0: ([132], [132], [0], [0], [100]),\n",
       "              1: ([83], [83], [1], [1], [100]),\n",
       "              2: ([385], [385], [2], [2], [100]),\n",
       "              3: ([81], [81], [3], [3], [100]),\n",
       "              4: ([113], [113], [4], [4], [100]),\n",
       "              5: ([357], [357], [5], [5], [100]),\n",
       "              6: ([245], [245], [6], [6], [100]),\n",
       "              7: ([39], [39], [7], [7], [100]),\n",
       "              8: ([45], [45], [8], [8], [100]),\n",
       "              9: ([162], [162], [9], [9], [100]),\n",
       "              10: ([101], [101], [10], [10], [100]),\n",
       "              11: ([385], [385], [11], [11], [100]),\n",
       "              12: ([95], [95], [12], [12], [100]),\n",
       "              13: ([34], [34], [13], [13], [100]),\n",
       "              14: ([200], [200], [14], [14], [100])}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm_best_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogenity best Cluster: 84.61 % to the other Clusterings\n",
      "Homogenity 2nd best Cluster: 85.36 % to the other Clusterings\n"
     ]
    }
   ],
   "source": [
    "homgenity_check_best = homogenity_check(gm_best_assignments, bm_best_assignments)\n",
    "homgenity_check_best2 = homogenity_check(gm_best2_assignments, bm_best2_assignments)\n",
    "\n",
    "print(\"Homogenity best Cluster:\", homgenity_check_best,\"% to the other Clusterings\")\n",
    "print(\"Homogenity 2nd best Cluster:\", homgenity_check_best2,\"% to the other Clusterings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with 2nd best Cluster.\n"
     ]
    }
   ],
   "source": [
    "if(homgenity_check_best >= homgenity_check_best2):\n",
    "    print(\"Continuing with best Cluster.\")\n",
    "    final_clusterscene = restore_real_rgb(best_clusterscene, pointcloud)\n",
    "    \n",
    "elif(homgenity_check_best2 > homgenity_check_best):\n",
    "    print(\"Continuing with 2nd best Cluster.\")\n",
    "    final_clusterscene = restore_real_rgb(best2_clusterscene, pointcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Creating an X,Y,Z,R,G,B,Label Pyntcloud. With normalized RGB.\n",
      "Automatic segmentation of pointcloud finished.\n"
     ]
    }
   ],
   "source": [
    "# Export clusters to file\n",
    "export_to_ply(final_clusterscene, normalized_rgb=1)\n",
    "\n",
    "# Export full scene to file\n",
    "full_final_clusterscene = numpy_to_pyntcloud(final_clusterscene, normalized_rgb=1)\n",
    "path = \"full_clusterscene_labeled.ply\"\n",
    "full_final_clusterscene.to_file(path)\n",
    "\n",
    "print(\"Automatic segmentation of pointcloud finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot selected Segment. Check if color assignment went right\n",
    "\n",
    "#final_segment = final_clusterscene[np.where(final_clusterscene[:,6] == 0)]\n",
    "#final_segment = numpy_to_pyntcloud(final_segment)\n",
    "#final_segment.plot()\n",
    "\n",
    "#cluster_to_mesh(final_clusterscene)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
