{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyntcloud import PyntCloud\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randint, uniform\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import time\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "#import open3d as o3d\n",
    "import scipy.io as io\n",
    "import scipy.ndimage as nd\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ User Settings ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# Set size of Voxels. The higher the better but can also be very slow with big Pointclouds\n",
    "voxel_size = 256\n",
    "\n",
    "# Restore the trained model\n",
    "if (voxel_size == 64):\n",
    "    model = tf.keras.models.load_model('savedmodel/scannet_model_64.h5')\n",
    "    print(\"CNN Model with Voxelsize of 64 has been loaded.\")\n",
    "\n",
    "if (voxel_size == 128):\n",
    "    model = tf.keras.models.load_model('savedmodel/scannet_model_128.h5')\n",
    "    print(\"CNN Model with Voxelsize of 128 has been loaded.\")\n",
    "    \n",
    "if (voxel_size == 192):\n",
    "    model = tf.keras.models.load_model('savedmodel/scannet_model_192.h5')\n",
    "    print(\"CNN Model with Voxelsize of 192 has been loaded.\")\n",
    "\n",
    "if (voxel_size == 256):\n",
    "    model = tf.keras.models.load_model('savedmodel/scannet_model_256.h5')\n",
    "    print(\"CNN Model with Voxelsize of 256 has been loaded.\")\n",
    "          \n",
    "# Clustering number of candidates 0-7\n",
    "n_candidates = 1\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Functions ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Colorizes the different Clusters randomly\n",
    "def colorize_pc(number_clusterpoints):\n",
    "\n",
    "    rgb = np.zeros((number_clusterpoints, 3), dtype=int)\n",
    "\n",
    "    r = randint(0, 254)\n",
    "    g = randint(0, 254)\n",
    "    b = randint(0, 254)\n",
    "\n",
    "    rgb_temp = np.array((r,g,b))\n",
    "    rgb = np.full_like(rgb,rgb_temp)\n",
    "\n",
    "    return rgb\n",
    "\n",
    "# Adding the Clusterlabel to the Clusters\n",
    "def add_clusterlabel(number_clusterpoints, clusterlabel):\n",
    "    \n",
    "    clusterlabel_array = np.zeros((number_clusterpoints,1), dtype=int)\n",
    "    clusterlabel_temp = np.array(clusterlabel)\n",
    "    clusterlabel_array = np.full_like(clusterlabel_array, clusterlabel_temp)\n",
    "    \n",
    "    return clusterlabel_array\n",
    "    \n",
    "\n",
    "# Colorize the points and returns a dataframe with rgb and a dataframe with labels\n",
    "def colorize_to_dataframe(clusters_dict, cnn_prediction):\n",
    "    \n",
    "    # Placeholder for the colorized Clusterscene (x,y,z,r,b,g(segment color), cluster_label)\n",
    "    cluster_scene = np.zeros((0, 7), dtype=float)\n",
    "    \n",
    "    clusterlabel = 0\n",
    "    for clusterlabel in range(cnn_prediction):\n",
    "        cluster = clusters_dict[clusterlabel]\n",
    "        number_clusterpoints = cluster.shape[0]\n",
    "        colorize_rgb = colorize_pc(number_clusterpoints)\n",
    "        \n",
    "        # Adding Color to cluster\n",
    "        cluster = np.hstack((cluster, colorize_rgb))\n",
    "\n",
    "        #Adding Clusterlabel to Cluster\n",
    "        cluster_label = add_clusterlabel(number_clusterpoints, clusterlabel)\n",
    "        cluster = np.hstack((cluster, cluster_label))\n",
    "        cluster_scene = np.append(cluster_scene, cluster, axis=0)\n",
    "         \n",
    "    x = cluster_scene[:, 0]\n",
    "    y = cluster_scene[:, 1]\n",
    "    z = cluster_scene[:, 2]\n",
    "    # Segment rgb Color\n",
    "    red = cluster_scene[:, 3]\n",
    "    green = cluster_scene[:, 4]\n",
    "    blue = cluster_scene[:, 5]\n",
    "    # Cluster Label\n",
    "    cluster_label = cluster_scene[:, 6]\n",
    "\n",
    "    df_cluster_scene_rgb = pd.DataFrame(zip(x, y, z, red, green, blue), columns=[\"x\", \"y\", \"z\", \"red\", \"green\", \"blue\"])\n",
    "    df_cluster_scene_labels = pd.DataFrame(zip(x, y, z, cluster_label), columns=[\"x\", \"y\", \"z\",\"cluster_label\"])\n",
    "    npy_cluster_scene_labels = df_cluster_scene_labels.to_numpy()\n",
    "        \n",
    "    return df_cluster_scene_rgb, npy_cluster_scene_labels\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "# load data from cvs    \n",
    "def load_cvs_data(path):\n",
    "    return np.loadtxt(path,delimiter=';')\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "def bubble_sort(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        for j in range(0, n-i-1):\n",
    "            # relative max occurence of label: arr[j][3][0]/arr[j][1]\n",
    "            #if arr[j][3][0]/arr[j][1] < arr[j+1][3][0]/arr[j+1][1]:\n",
    "            if arr[j][3].max() < arr[j+1][3].max():\n",
    "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
    "    return arr\n",
    "\n",
    "# compute an error per false clustered point\n",
    "def compute_error(all_points, labels, orig_labels, orig_indices, orig_counts):\n",
    "    assignments = {}\n",
    "    # the total error\n",
    "    error = 0\n",
    "    # iterate over all clusters\n",
    "\n",
    "    intervals = []\n",
    "\n",
    "    label_values, label_counts = np.unique(labels, return_counts = True)\n",
    "    orig_values, orig_label_counts = np.unique(all_points[:,3] , return_counts = True)\n",
    "\n",
    "    #print(label_values, orig_values)\n",
    "    #print(label_counts, orig_label_counts)\n",
    "\n",
    "    diff = np.absolute(orig_label_counts.shape[0] - label_counts.shape[0])\n",
    "\n",
    "    for i in range(orig_labels.shape[0]):\n",
    "        idx = orig_indices[i]\n",
    "        count = orig_counts[i]\n",
    "        obj_labels = labels[idx : idx + count]\n",
    "        #print(obj_labels)\n",
    "        sorted_labels, obj_counts = np.unique(obj_labels, return_counts=True)\n",
    "        intervals.append( (idx, count, sorted_labels, obj_counts) )\n",
    "        #print(obj_counts.max())\n",
    "\n",
    "    intervals = bubble_sort(intervals)\n",
    "    n_unlabelled_points = 0\n",
    "    for i in range(len(intervals)):\n",
    "        obj_idx = intervals[i][0]\n",
    "        len_points = intervals[i][1]\n",
    "        sorted_labels = intervals[i][2]\n",
    "        counts = intervals[i][3]\n",
    "        #print(len_points, counts)\n",
    "\n",
    "        # if label == -1 -> continue\n",
    "\n",
    "        # the labels have the same shape as the point cloud hence we do not need to search over the points to know the original labels\n",
    "        obj_labels = labels[obj_idx:obj_idx+len_points]\n",
    "\n",
    "        n_unlabelled_points += len(np.argwhere(obj_labels == -1))\n",
    "\n",
    "        #print(labels[last_len_points:last_len_points+len_points], new_labels, counts, len_points)\n",
    "        #print(obj_labels, sorted_labels)\n",
    "        # check if a label is already assigned\n",
    "        is_already_assigned = True\n",
    "        # check if a label is available\n",
    "        no_label_available = False\n",
    "\n",
    "        while is_already_assigned:\n",
    "            # no more label available for assignment - this happens if there are less cluster than predicted\n",
    "            if counts.size == 0:\n",
    "                no_label_available = True\n",
    "                break\n",
    "            # get the index of the most frequent cluster\n",
    "            j = np.argmax(counts)\n",
    "            # get the most frequent cluster label\n",
    "            if sorted_labels[j] == -1:\n",
    "                is_already_assigned = True\n",
    "            else:\n",
    "                chosen_label = sorted_labels[j]\n",
    "                # check if label is already assigned\n",
    "                is_already_assigned = chosen_label in assignments.values()\n",
    "            if(is_already_assigned):\n",
    "                # if so delete the label and take the second most label and so forth\n",
    "                sorted_labels = np.delete(sorted_labels, j)\n",
    "                counts = np.delete(counts, j)\n",
    "            else:\n",
    "                break\n",
    "        # if there are no more labels, consider all the points as misclustered\n",
    "        # n_labels > n_orig_labels\n",
    "        if no_label_available:\n",
    "            false_points = np.argwhere(obj_labels != -1)\n",
    "            error += len(false_points)\n",
    "        else:\n",
    "            # save the assignet label for next iterations\n",
    "            assignments[i] = chosen_label\n",
    "            #print(assignments)\n",
    "            # filter the objec\tts with the wrong labels\n",
    "            false_points = np.argwhere(obj_labels != chosen_label)\n",
    "            false_points = np.argwhere(obj_labels[false_points] != -1)\n",
    "            # increment the error for every false point\n",
    "            error += len(false_points)\n",
    "        #print(error)\n",
    "    return error, assignments # n_unlabelled_points, diff, \n",
    "\n",
    "def compute_intervals(all_points):\n",
    "    orig_labels, orig_indices, orig_counts = np.unique(all_points[:,3], return_index = True, return_counts = True)\n",
    "    return orig_labels, orig_indices, orig_counts\n",
    "\n",
    "def sort_point_cloud(all_points):\n",
    "    all_points = all_points[all_points[:,3].argsort(kind='mergesort')]\n",
    "    return all_points\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "def remove_every_other(my_list):\n",
    "    return my_list[::2]\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Start  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\"\"\"\n",
    "Scannet Data: \n",
    "\n",
    "1) vh_clean_2.labels.ply = Colorized Segments + Label\n",
    "\n",
    "2) vh_clean_2.ply = Real RGB Colors - Labels but same Number of Points as 1)\n",
    "\"\"\"\n",
    "\n",
    "# Get RGB Pointcloud and Labels\n",
    "DATADIR = \"G:\\datasets\\scannet_ply_rgb\\scans\\\\\"\n",
    "DATADIR_labels = \"G:\\datasets\\scannet_ply_labels\\scans\\\\\"\n",
    "\n",
    "folder = random.choice(os.listdir(DATADIR))\n",
    "path = DATADIR + folder\n",
    "file = next(os.walk(path))[2][0]\n",
    "path = path +\"\\\\\"+ file\n",
    "\n",
    "# Load Data to PyntCloud Object\n",
    "pointcloud_rgb = PyntCloud.from_file(path)  #Format: x,y,z, r, g, b, alpha\n",
    "initial_pointcloud = PyntCloud.from_file(path)\n",
    "del pointcloud_rgb.points['alpha'] \n",
    "\n",
    "#~~~~~\n",
    "path_labels = DATADIR_labels + folder + \"\\\\\"\n",
    "file_labels = next(os.walk(path_labels))[2][0]\n",
    "path_labels = path_labels + file_labels\n",
    "\n",
    "# Load Data to PyntCloud Object\n",
    "pointcloud_labels = PyntCloud.from_file(path_labels)  # Format: x,y,z, seg r, seg g, seg b,alpha,label\n",
    "\n",
    "# Creating Pointcloud with rgb and labels\n",
    "pointcloud_rgb.points['label'] = pointcloud_labels.points['label']\n",
    "\n",
    "# Convert to npy for manipulation\n",
    "npy_pointcloud = pointcloud_rgb.points.to_numpy()\n",
    "\n",
    "# Sort the Pointcloud after labels\n",
    "pointcloud_rgb = sort_point_cloud(npy_pointcloud)\n",
    "\n",
    "# Get Number of Objects in the Scene\n",
    "category = pointcloud_rgb[:, 6]\n",
    "category = np.unique(category) # counts only each unique number\n",
    "number_objects = category.shape[0]\n",
    "\n",
    "#pointcloud_rgb = remove_every_other(pointcloud_rgb)\n",
    "\n",
    "print(\"Number of Objects:\", number_objects)\n",
    "\n",
    "# Create pandas dateframe to convert x,y,z scene to pyntcloud Object\n",
    "p_x = pointcloud_rgb[:, 0]\n",
    "p_y = pointcloud_rgb[:, 1]\n",
    "p_z = pointcloud_rgb[:, 2]\n",
    "\n",
    "p_r = pointcloud_rgb[:, 3] \n",
    "p_g = pointcloud_rgb[:, 4] \n",
    "p_b = pointcloud_rgb[:, 5]\n",
    "p_label = pointcloud_rgb[:, 6]\n",
    "\n",
    "df_pointcloud = pd.DataFrame(zip(p_x, p_y, p_z, p_r, p_g, p_b, p_label ),\n",
    "                             columns=['x', 'y', 'z','red','green','blue', 'label']) # In Pnytcloud it has to be 'red', 'green', 'blue',\n",
    "\n",
    "df_pointcloud_label = pd.DataFrame(zip(p_x, p_y, p_z,p_label ),\n",
    "                                   columns=['x', 'y', 'z','label'])\n",
    "\n",
    "pointcloud_label = df_pointcloud_label.to_numpy()\n",
    "\n",
    "\n",
    "pointcloud_rgb = PyntCloud(df_pointcloud)\n",
    "pointcloud_rgb.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Prepare Data for input in CNN ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# Voxelgrid only takes the XYZ Informations\n",
    "voxelgrid_id = pointcloud_rgb.add_structure(\"voxelgrid\", n_x = voxel_size, n_y = voxel_size, n_z = voxel_size)\n",
    "voxelscene = pointcloud_rgb.structures[voxelgrid_id]\n",
    "\n",
    "# Create binary array from Voxelscene\n",
    "binary_voxelscene = voxelscene.get_feature_vector(mode=\"binary\")\n",
    "\n",
    "# Prepare data for Network input\n",
    "# A 3D Cnn expects an 4D Tensor as Input\n",
    "binary_voxelscene = np.expand_dims(binary_voxelscene, axis=0)\n",
    "\n",
    "# CNN prediction\n",
    "cnn_out = model.predict(binary_voxelscene)\n",
    "cnn_prediction = np.argmax(cnn_out)\n",
    "\n",
    "print(\"Predicted Numbers of Objects:\", cnn_prediction)\n",
    "print(\"real number of Objects:\", number_objects)\n",
    "\n",
    "if cnn_prediction != number_objects:\n",
    "    cnn_prediction = number_objects\n",
    "    print(\"False Number of Objects detected. Continuuing with real data for testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ CLUSTERING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "#Prepare Pointcloud for Clustering\n",
    "\n",
    "cluster_pointcloud = pointcloud_rgb.xyz\n",
    "\n",
    "\n",
    "# Setting up the Clustering Candidates\n",
    "gaussian_clustering = GaussianMixture(n_components=cnn_prediction, covariance_type='full',tol=1e-4, max_iter=400)\n",
    "bayesian_clustering = BayesianGaussianMixture(n_components=cnn_prediction, \n",
    "                                              covariance_type='full',tol=1e-4, max_iter=400)\n",
    "\n",
    "gaussian_clustering2 = GaussianMixture(n_components=cnn_prediction, covariance_type='full',tol=1e-5, max_iter=500)\n",
    "bayesian_clustering2 = BayesianGaussianMixture(n_components=cnn_prediction, \n",
    "                                               covariance_type='full',tol=1e-5, max_iter=500)\n",
    "\n",
    "gaussian_clustering3 = GaussianMixture(n_components=cnn_prediction, covariance_type='full',tol=1e-6, max_iter=800)\n",
    "bayesian_clustering3 = BayesianGaussianMixture(n_components=cnn_prediction, \n",
    "                                               covariance_type='full',tol=1e-6, max_iter=800)\n",
    "\n",
    "gaussian_clustering4 = GaussianMixture(n_components=cnn_prediction, covariance_type='full',tol=1e-7, max_iter=1000)\n",
    "bayesian_clustering4= BayesianGaussianMixture(n_components=cnn_prediction, \n",
    "                                              covariance_type='full',tol=1e-7, max_iter=1000)\n",
    "\n",
    "gaussian_clustering5 = GaussianMixture(n_components=cnn_prediction, covariance_type='full',tol=1e-8, max_iter=1500)\n",
    "bayesian_clustering5 = BayesianGaussianMixture(n_components=cnn_prediction, \n",
    "                                              covariance_type='full',tol=1e-8, max_iter=1500)\n",
    "\n",
    "gaussian_clustering6 = GaussianMixture(n_components=cnn_prediction, covariance_type='full',tol=1e-9, max_iter=2000)\n",
    "bayesian_clustering6 = BayesianGaussianMixture(n_components=cnn_prediction,\n",
    "                                              covariance_type='full',tol=1e-9, max_iter=2000)\n",
    "\n",
    "gaussian_clustering7 = GaussianMixture(n_components=cnn_prediction, covariance_type='diag',tol=1e-4, max_iter=500)\n",
    "bayesian_clustering7 = BayesianGaussianMixture(n_components=cnn_prediction,\n",
    "                                              covariance_type='diag',tol=1e-4, max_iter=500)\n",
    "\n",
    "gaussian_clustering8 = GaussianMixture(n_components=cnn_prediction, covariance_type='diag',tol=1e-6, max_iter=800)\n",
    "bayesian_clustering8 = BayesianGaussianMixture(n_components=cnn_prediction,\n",
    "                                              covariance_type='diag',tol=1e-6, max_iter=800)\n",
    "\n",
    "# List of Labels per Clustering\n",
    "gm ={}\n",
    "gm_labels={}\n",
    "bm={}\n",
    "bm_labels={}\n",
    "\n",
    "gm_clusters_dict={}\n",
    "gm_clusterscene_rgb={}\n",
    "gm_clusterscene_labels={}\n",
    "\n",
    "bm_clusters_dict={}\n",
    "bm_clusterscene_rgb={}\n",
    "bm_clusterscene_labels={}\n",
    "\n",
    "gm_clusterscene_rgb_pynt={}\n",
    "bm_clusterscene_rgb_pynt ={}\n",
    "\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "while i <= n_candidates:\n",
    "    \n",
    "    if i == 0:\n",
    "        print(\"full 1\")\n",
    "        gm[i] = gaussian_clustering.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering.predict(cluster_pointcloud) \n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        \n",
    "    if i == 1:\n",
    "        print(\"full 2\")\n",
    "        gm[i] = gaussian_clustering2.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering2.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering2.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering2.predict(cluster_pointcloud)\n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        \n",
    "    if i == 2:\n",
    "        print(\"full 3\")\n",
    "        gm[i] = gaussian_clustering3.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering3.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering3.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering3.predict(pointcloud)\n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        \n",
    "    if i == 3:\n",
    "        print(\"full 4\")\n",
    "        gm[i] = gaussian_clustering4.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering4.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering4.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering4.predict(cluster_pointcloud)\n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        \n",
    "    if i == 4:\n",
    "        print(\"full 5\")        \n",
    "        gm[i] = gaussian_clustering5.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering5.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering5.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering5.predict(cluster_pointcloud)\n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        \n",
    "    if i == 5:\n",
    "        print(\"full 6\")        \n",
    "        gm[i] = gaussian_clustering6.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering6.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering6.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering6.predict(cluster_pointcloud)\n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "    \n",
    "    if i == 6:\n",
    "        print(\"diag 1\")        \n",
    "        gm[i] = gaussian_clustering7.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering7.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering7.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering7.predict(cluster_pointcloud)\n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "    \n",
    "    if i == 5:\n",
    "        print(\"diag 2\")        \n",
    "        gm[i] = gaussian_clustering8.fit(cluster_pointcloud)\n",
    "        gm_labels[i] = gaussian_clustering8.predict(cluster_pointcloud)\n",
    "        bm[i] = bayesian_clustering8.fit(cluster_pointcloud)\n",
    "        bm_labels[i] = bayesian_clustering8.predict(cluster_pointcloud)\n",
    "        gm_clusters_dict[i] = {j: cluster_pointcloud[np.where(gm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        bm_clusters_dict[i] = {j: cluster_pointcloud[np.where(bm_labels[i] == j)[0]] for j in range(cnn_prediction)}\n",
    "        \n",
    "    # Colorize Clusters and adding Clusterlabels\n",
    "    \n",
    "    gm_clusterscene_rgb[i], gm_clusterscene_labels[i] = colorize_to_dataframe(gm_clusters_dict[i], cnn_prediction)\n",
    "    bm_clusterscene_rgb[i], bm_clusterscene_labels[i] = colorize_to_dataframe(bm_clusters_dict[i], cnn_prediction)\n",
    "    \n",
    "    gm_clusterscene_rgb_pynt[i] = PyntCloud(gm_clusterscene_rgb[i])\n",
    "    bm_clusterscene_rgb_pynt[i] = PyntCloud(gm_clusterscene_rgb[i])\n",
    "    \n",
    "    gm_clusterscene_rgb_pynt[i].plot(initial_point_size=0.1)\n",
    "    bm_clusterscene_rgb_pynt[i].plot(initial_point_size=0.1)\n",
    "    \n",
    "    print(\"Cluster\", i+1, \"from\", n_candidates+1, \"done.\")\n",
    "\n",
    "    i=i+1\n",
    "    \n",
    "\n",
    "print(\"Segmentation done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Score Calc possible\n",
    "\n",
    "initial_pointcloud = pointcloud_label\n",
    "\n",
    "if gm_clusterscene_labels[0].shape != initial_pointcloud.shape:\n",
    "    print(\"Score Calc not possible. Segmentated Pointclouds need to be the same size as Initial Pointcloud\")\n",
    "    print(gm_clusterscene_labels[0].shape)\n",
    "    print(initial_pointcloud.shape)\n",
    "    error_check = 0\n",
    "else:\n",
    "    run_count=1 # Only for testenvironment\n",
    "    error_check = 1\n",
    "    print(\"Score calulation possible\")\n",
    "    \n",
    "    # ------------------------------------- Error calculation of Clusters --------------------------------------------------\n",
    "if error_check == 1: \n",
    "    \n",
    "    if run_count == 1: # Only for the test environment can be deleted in normal build\n",
    "\n",
    "        # Ground Truth Pointcloud\n",
    "        orig_labels, orig_indices, orig_counts = compute_intervals(initial_pointcloud)\n",
    "        initial_n_points = initial_pointcloud.shape[0]\n",
    "\n",
    "    run_count = 0\n",
    "\n",
    "\n",
    "    #Calculate Score for each Cluster Methods Cluster\n",
    "    gm_n_errornous_points = {}\n",
    "    gm_assignments = {}\n",
    "    gm_error = {}\n",
    "\n",
    "    bm_n_errornous_points = {}\n",
    "    bm_assignments = {}\n",
    "    bm_error ={}\n",
    "\n",
    "    i = 0\n",
    "    while i <= n_candidates:\n",
    "\n",
    "        if i == 0:\n",
    "\n",
    "            #Ground Trouth Only for TESTING! should be 1\n",
    "            gt_n_errornous_points, gt_assignments = compute_error(initial_pointcloud, initial_pointcloud[:,3],\n",
    "                                                                  orig_labels, orig_indices, orig_counts)\n",
    "            gt_error = 1 - ((gt_n_errornous_points)/initial_n_points)\n",
    "            print(\"Error Ground Thruth\", gt_error)\n",
    "\n",
    "        gm_n_errornous_points[i], gm_assignments[i] = compute_error(initial_pointcloud, gm_clusterscene_labels[i][:,3],\n",
    "                                                              orig_labels, orig_indices, orig_counts)\n",
    "\n",
    "        bm_n_errornous_points[i], bm_assignments[i] = compute_error(initial_pointcloud, bm_clusterscene_labels[i][:,3],\n",
    "                                                              orig_labels, orig_indices, orig_counts)\n",
    "\n",
    "        # Statistics\n",
    "        gm_error[i] = 1 - ((gm_n_errornous_points[i])/initial_n_points)\n",
    "        bm_error[i] = 1 - ((bm_n_errornous_points[i])/initial_n_points)\n",
    "\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "        print(\"Error Gaussian Clustering with Setup:\", gm[i], \"lead to an Error of:\", gm_error[i])\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "        print(\"Error Bayesian Clustering with Setup:\", bm[i], \"lead to an Error of:\", bm_error[i])\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "        i=i+1\n",
    "\n",
    "    print(\"Error calculation done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
